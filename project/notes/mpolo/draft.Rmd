- vedi GAM da lab 8/ ultime slide
  - spline puoi usarle anche su GLM ma la differenza è che GAM ha una penalizzazione nel fitting che GLM non ha quindi non è la stessa cosa (https://stats.stackexchange.com/a/298831 o lab 8): quando le specifichi su GLM (con `bs()`) specifichi anche il grado dei polinomi (e quindi numero di coefficienti) e fai linear regression sui coefficienti, invece su GAM le specifichi non-parametriche (con `s()`) e ci pensa il fitting a trovare le migliori (smoothin regression): https://stats.stackexchange.com/a/517784

- vedi dataset per capire quale family usare per GAM/GLM (gaussian, poisson, binomial, negative binomial)
  - y é multiclass ma con classi ordinate, però credo che nessuna delle famiglie che abbiamo visto vada bene. Serve famiglia che modelli ordered categorical data (diverso da count della poisson o negative binomial perché limitate). Per multiclass di solito si usa multinomial (che forse non abbiamo fatto). Ma visto che le nostre sono ordered non trascurerei questo fatto e farei ordinal logistic regression quindi con family ordinal (che non credo abbiamo fatto, e forse è da importare o usare altra API rispetto `glm`). Inoltre neanche l'API `glmnet` per lasso penso abbia ordinal, però ha multinomial
    - anzi imo vai easy con linear regression (family gaussian, o usa direttamente)
  - per alberi invece non credo esista ordinal regression. o fai regression o classification. Differenza è tipo che in regression se 2 alberi predicono 5 e 3 predicono 7, viene classificato come 6 (ma devi fare tu qualche trick per arrotondare), mentre in classification come 7.

- Per interpretabilità random forest (e boosting) vedi slide alberi, oppure anche slide machine learning di Medved, e vedi se per caso c'è già modo easy in R (in teoria sì, vedi i mean decrease alla fine del lab 8)

- forse serve vedere anche correlazione tra le variabili come in lab 8. Ma dopo che te ne fai? scarti le predictor correlate tra loro?
  - Correlated variables in a dataset can lead to multicollinearity, which can affect the interpretation of the coefficients. It's generally recommended to address correlated variables when training a GLM. One way to do this is by discarding one of the correlated variables. Another way is to use regularization techniques such as Lasso, which can help to reduce the impact of correlated variables on the model by shrinking the coefficients of correlated variables.

- Lasso dovrebbe essere generalizzazione di GLM quindi basta quello imo (con lambda=0 è GLM normale penso, ma non so se la  sua API `glmnet` permette di fare le stesse cose). Vedi [qui](https://stackoverflow.com/a/38378121) per confronto risultati con glm normale per vedere se si sta facendo bene. IMO usa cv.glmnet per trovare lambda migliore. Fa così anche libro.

- models (fai linear regression):
  - gaussian glm (or lm but less cool)
    - tutte variabili così come sono più tutte interaction primo grado e basta (niente quadrati)
  - gaussian gam
    - spline di tutte le variabili così come sono e basta
  - random forest
  - boosting (se c'è tempo, meglio no)

  
**TODO**:
* exploratory data analysis
  * che roba è? (forse vedi link consigliato da prof, o link agustin)
  * data cleaning
    * capisci se numeriche, categoriche (e in caso usa factor in lasso, gam)
    * vedi se ci sono NA
    * vedi se ci sono outliers (rimuovi con 3sigma rule, log se non normal? o metodo con quantili che dice agustin?)
    * togli i dati più correlati e testa i modelli con e senza
      * dovrebbero dare problemi su glm (anche se forse meno con lasso) e gam
    * vedi se valori alti e serve normalizzare/standardizzare per glm/lasso e gam?
    * che altro?

* modelli
  * random forest
    * quality senza factor per regression
    * test set (c'è opzione)?
      * forse usa out-of-bag quindi non serve?
    * niente tuning?
      * se ha stessi parametri di default di scikit learn, no
        * unico tuning da fare è nei dati in questo caso imo
    * mtry è da cambiare? cosa fa scikit learn?
    * fai cosa viene fatto in lab8
    * assicurati che abbia senso togliere outliers e che non abbia senso fare feature selection
* lasso (glmnet)
  * non fai feature selection manuale con AIC, ma fai fare a lui, semplicemnte prendi migliore lambda in base a CV che fa
  * interaction va bene per le non categorie? da testare
* gam fai solo spline per ogni feature e fai grid search come su lab 8, per trovare i lambda ottimali di ogni spline

* conclusioni:
  * train test split? (no per fine tuning lasso e gam, perché AIC viene fatto su training set e va bene così) (lasso cmq fa CV per trovarsi il lambda ma non splitti comunque tu prima i dati).
    * confronto tra modelli: devi fare con CV.. vedi se come.. forse esiste cv.glmnet, ecc.
    * splitta train test,
      * test non tocchi
      * train ci fitti 6 modelli (3 con tutto train e 3 senza i 3 sigma) e li confronti tutti su test set con MSE
        * a random forest in teoria puoi passarlo il test set
        * glmnet? TODO
        * gam? TODO

---

# Description of the project’s aim

TBD

# Exploratory data analysis

TBD (including a possible data-cleaning phase)

```{r}
#load dataset
df = read.csv("../../winequality-white.csv", sep=";")
x = subset(df, select=-quality)
y = subset(df, select=quality)
```

# Selection, description, and comparison of the most suitable statistical models

TBD

```{r}
#fit models
library(glmnet)
library(mgcv)
library(randomForest) #v 4.6-14 for R 4.0.4

glmnet_ = #glmnet(x = data.matrix(x), y = data.matrix(y))
gam_ = 
rf_ = randomForest(quality ~ ., data = df, importance=TRUE)
#boosting?
```

```{r}
#mse comparison (test set)

#lasso
assess.glmnet(glmnet(x = data.matrix(x), y = data.matrix(y), lambda=0.6), newx=data.matrix(x), newy=data.matrix(y))

#random forest ha opzione per passare test set mentre fitti
rf_ = randomForest(quality ~ ., data = df, importance=TRUE, xtest=x, ytest=data.matrix(y))
rf_$test #ma forse meglio prendere mse che ti danno gli out of bag (fatti apposta)

#gam (esempio)
n<-200
sig <- 2
dat <- gamSim(1,n=n,scale=sig)

b<-gam(y~s(x0)+s(I(x1^2))+s(x2)+offset(x3),data=dat)

newd <- data.frame(x0=(0:30)/30,x1=(0:30)/30,x2=(0:30)/30,x3=(0:30)/30)
actual = rep(5, 31)
pred <- predict.gam(b,newd)
mse = mean((pred - actual)^2) #actual non definito in questo esempio
mse
```

```{r}
importance(forest)
rf_
```

```{r}
varImpPlot(forest, sort=TRUE)
```

## Comments on results
