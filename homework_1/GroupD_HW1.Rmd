---
title: "GroupD_HW1"
author: "G. Marsich, M. Vicari, M. Polo, E. Malcapi"
date: "2022-10-20"
output:
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
  pdf_document:
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## FSDS - Chapter 1

### Ex 1.41

*To investigate how *$\overline{y}$ *can vary from sample to sample of size n, for the simulation from  a bell-shaped population shown at the end of Section 1.5.3, take (a) 10,000 random  samples of size n = 30 each; (b) 10,000 random samples of size n = 1000 each. In  each case, form a histogram of the 10,000 *$\overline{y}$ *values and find their standard deviation.  Compare results and explain what this simulation reveals about the impact of sample  size on how study results can vary. (Chapter 3 shows that in sampling from a population  with standard deviation 16, the theoretical standard deviation of *$\overline{y}$ *values is* $16/\sqrt n$ *) *




**Solution**

we take 10.000 random samples of size n = 30 and n = 1000 both for a simulation a bell-shaped population (using rnorm) and we evaluate the mean in each iteration of all the random samples and store them (in the following code y1 for n = 30 size and y2 for n = 1000 size). 
Then we calculate the mean and standard deviation and compare them.

```{r ex 1.41, echo=TRUE}
randomSample <- 10000
y1 <- y2 <- rep(NA,randomSample)

for (i in 1:randomSample) {
  y1[i] <- mean(rnorm(30,100,16))
  y2[i] <- mean(rnorm(1000,100,16))
}
mean(y1);sd(y1);hist(y1)
mean(y2);sd(y2);hist(y2)
```

In the second case we can see that we have a smaller standard deviation so data are more clustered to the mean than the first case.

In the last part of the exercise we compare the theoretical formula (sampling from a population with standard deviation 16, the theoretical standard deviation of $\overline{y}$ values is $16/\sqrt n$)

```{r comparison with theoretical sd formula, echo=TRUE}
16/sqrt(30)
16/sqrt(1000)

```
they are the approximate same results of the previous standard deviations found


### Ex 1.43
*For a sample with mean $\bar y$, show that adding a constant $c$ to each observation changes the mean to $\bar y + c$, and the standard deviation s is unchanged. Show that multiplying each observation by $c$ changes the mean to $c \bar y$ and the standard deviation to $|c|s$.*


**Solution**

First we crate a sample of 1000 elements with a p.d.f. $N(4,3)$, and evaluate the mean and standard deviation:
```{r, echo=T}
#Create the sample
b <- rnorm(n=1000,4,3)
#Evaluate the mean and standard deviation 
mean=mean(b)
s_deviaition=sd(b)
```
Now we create a second sample by adding to each element of the first sample the costant $c=2$, and then we compare the mean and standard deviation of the two samples:
```{r, echo=T}
#Adds c=2 to each element of the sample 
c=2
b1=b+c
#Compare the mean and standard deviation  
mean1=mean(b1)
s_deviation1=sd(b1)
print("mean of the first sample +c: ", mean+c)
print("mean of the second sample: ",mean1)
print("standard deviation of the first sample: ",s.deviation)
print("standard deviation of the second sample: ",s.deviation1)
```
Now we create the second sample by moltypling the elements of the first one by $c=2$, and compare again the mean and standard deviation:
```{r, echo=T}
#multiply the valuse by c=2
b1=c*b
#Compare the mean and variance  
mean1=mean(b1)
s.deviation1=sd(b1)
print("mean of the first sample times c: ", mean*c)
print("mean of the second sample: ",mean1)
print("standard deviation of the first sample times c^2: ",s.deviation*c**2)
print("standard deviation of the second sample: ",s.deviation1)

```


### Ex 1.44

*Suppose the sample data distribution of* $\{y_i\} = \{y_1,...,y_n\}$ *is very highly skewed to the right, and we take logs and analyze* $\{x_i = log(y_i)\}$*.*

a. *Is* $\bar x = log(\bar y)$*? Why or why not?*
b. *Is* $median(\{x_i\}) = log[median(\{y_i\})]$? *Why or why not?*
c. *To summarize* $\{y_i\}$, we find $\bar x$ and then use $exp(\bar x)$*. Show that* $\begin{matrix} exp(\bar x) = (\prod_i y_i)^{1/n} \end{matrix}$*, called the geometric mean of* $\{y_i\}$*.*

**Solution**

**(a)** <br>
No, because there is at least one counterexample:

```{r, echo=T}
y = rgamma(n=100, shape=2)
x = log(y)

mean(x); log(mean(y))
```

**(b)** <br>
No, because there is at least one counterexample:

```{r, echo=T}
y = rgamma(n=2, shape=2)
x = log(y)

median(x); log(median(y))
```

However, for larger $n$ they tend to be closer, and for odd $n$ they are equal because $log$ is a monotonically increasing function so it preserves the sample order.

**(c)** <br>
They are equal:

$$
exp(\bar x) = exp \left( {1\over n} \sum_i x_i \right) = exp \left( {1\over n} \sum_i log(y_i) \right) = \\
exp \left( \sum_i log(y_i^{1/n}) \right) = \prod_i exp[log(y_i^{1/n})] =
\left( \prod_i y_i \right)^{1/n}
$$

### Ex 1.48

*For a sample* $\{y_i\}$ *of size* $n$*,* $\begin{matrix} \sum_i \left| y_i-c \right| \end{matrix}$ *is minimized at* $c$ *= median. Explain why this property holds. (Hint: Starting at* $c$ *= median, what happens to* $\begin{matrix} \sum_i \left| y_i-c \right| \end{matrix}$ *as you move away from it in either direction?)*

**Solution**

Let the observations be ordered, let $c$ = median, let $a = c+\Delta$ and let $m$ be the number of observations smaller than $a$. <br>
If $\Delta > 0$ ("moving away from the median to the right") then $m \ge {n\over2}$; else if $\Delta < 0$ ("moving away from the median to the left") then $m \le {n\over2}$ (let's call these remarks "rem 1"). <br>
Let's demonstrate that $\begin{matrix} \sum_i \left| y_i-a \right| \ge \sum_i \left| y_i-c \right| \end{matrix}$:

$$
\sum_{i=1}^n \left| y_i-a \right| =
\sum_{i=1}^m [(c+\Delta)-y_i] + \sum_{i=m+1}^n [y_i - (c+\Delta)] = \\
m\Delta + \sum_{i=1}^m (c-y_i) - (n-m)\Delta + \sum_{i=m+1}^n (y_i-c) \overset{\text{rem 1}}= \\
2m\Delta-n\Delta + \sum_{i=1}^n \left| y_i-c \right| \ge \sum_{i=1}^n \left| y_i-c \right|
$$

So $\begin{matrix} \sum_i \left| y_i-c \right| \end{matrix}$ is minimized at $c$ = median.

## FSDS - Chapter 2

### Ex 2.3
*According to recent data at the FBI website, of all Blacks slain in the U.S., $85%$ are slain by Blacks, and of all Whites slain, $93%$ are slain by Whites. Let $Y = victim’s race$ and $X = offender’s race$.*

1. *Which conditional distribution do these probabilities refer to, $Y$ given $X$, or $X$ given $Y$ ?*
2. *Given that a murderer was White, what other probability do you need to estimate the conditional probability that the victim was White? To illustrate, fix a value of $0.60$ for that other probability and find the conditional probability.*


**Solution**


1. The conditional distribution we are referring is $P(X|Y)$ since we are considering the probability that $X=white\: or\: black$ *among the all population* of white or black victim $(Y)$
2. For the Bayes theorem we have that:
$$
P(Y=white|X=white)=\frac{P(Y=white)P(X=white|Y=white)}{P(X=white)}
$$
But from $\frac{P(X\cap Y_i)}{P(Y_i)}=P(X|Y_i)$ it follows that $P(X)=\sum_iP(Y_i)P(X|Y_i)$, so we can obtain: 
$$
P(Y=white|X=white)=\frac{P(Y=white)P(X=white|Y=white)}{P(Y=white)P(X=white|Y=white)+P(Y=blacck)P(X=white|Y=black)}
$$
Having the value of $P(Y=white)=0.6$ we obtain $P(Y=white|X=white)=0.90$

### Ex 2.5

*Suppose that a person is equally likely to be born on any of 365 days of the year.*  

*(a) For three people selected randomly, explain why the probability that they all have different  birthdays is [(365)(364)(363)]/365^3.*  

*(b) Show that if at least 23 people attend a social party, the probability exceeds 0.50 that at  least two people have the same birthday. State any further assumptions needed for your  solution. (The R function pbirthday(n) gives the probability that at least 2 of n people  have the same birthday.)* 

*(c) Use a simulation to show that if 50 people attend the party, the probability is 0.97 of at  least one common birthday. (If results seem counterintuitive, notice how the number of  pairs of attendees increases as the number of attendees n increases.)  *

**Solution**

a) that is because these are indipendent events. In the numerator, we multiply 365 for 364 because we do not want the second person to be born the same day of the first person and then for 363 because we do not want the third person to be born the same day than the others.

b)
The event of at least two of the n persons having the same birthday is complementary to all n birthdays being different.

```{r part b ex 2.5, echo=TRUE}
o <- 365
pr <- 1/365
res <- 1
for (i in 1:23 ) {
  res = res * pr * o 
  cat(i, " -- ",1 - res)
  print(' ')
  o = o - 1
  
}
#same result with pbirthday function
#for (i in 1:50 ) {
#  cat(" - it",i, "with p:",1 - pbirthday(i))}
```


Probability that at least 2 out of 23 have the same birthday is 1 − 0.493 = 0.507

c)

the following loop create 100000 times a sample of 50 observation of people's birthday attending a party( with the unique() function duplicates are removed so the variable ind is 1 everytime the sample has duplicates). At the end we divide ind with total number of samples to get the probability

```{r part c ex 2.5, echo=TRUE}
ind<-0;iter<- 100000
for(i in 1:iter){
  s<-sample(1:365,50,replace=TRUE);d<- unique(s)
  ind<-ind+as.numeric(length(d)!=length(s)) }
ind/iter
```

### Ex 2.7 

*For the simulation at the end of Section 2.3.1, explain why you could also simulate the mean  with a single binomial experiment of 30 million observations and probability 0.50 of a head for  each, dividing by 10,000,000. Do this and compare the result to the theoretical expected value.  *

**Solution**


```{r ex 2.7, echo=TRUE}
y <- rbinom(10000000,3,0.50) #the following simulate 10000000 times the no. of successes in 3 trials.
head(y, 10)
mean(y)
sd(y)

rbinom(1,30000000,0.50)/10000000 #this simulate what the exercise is asking to do.
```

let's explain why this gives us the same result with a very simplified example (useful only to understand the problem):

yx <- rbinom(10,3,0.50) 
with result:
1 2 1 2 0 1 2 2 1 3
so the mean is 
(0+ 4 * 1 + 4 * 2 + 1 * 3)/10 
with 10 number of samples

that is the same if we take a single sample of 10 trials that
give us 15 success and then we divide by 10
15/10

that is the same of the theoretical expected value is 1.5000 (that is p * n = 0.5 * 3).


### Ex 2.16

*Each day a hospital records the number of people who come to the emergency room for treatment.*

a. *In the first week, the observations from Sunday to Saturday are 10, 8, 14, 7, 21, 44, 60. Do you think that the Poisson distribution might describe the random variability of this phenomenon adequately. Why or why not?*
b. *Would you expect the Poisson distribution to better describe, or more poorly describe, the number of weekly admissions to the hospital for a rare disease? Why?*

**Solution**

**(a)** <br>
No, because the Poisson distribution has mean = variance, while our sample has very different values:

```{r, echo=T}
x = c(10, 8, 14, 7, 21, 44, 60)
mean(x); var(x)
```

**(b)** <br>
The Poisson distribution assumes that the events occur independently and at a constant average rate. So we expect it to better describe weekly admissions for a rare disease than daily admissions for a generic treatment. In fact:

  * We expect rare diseases to occur more independently than other causes of hospitalization (eg.: car accidents may involve more people).
  * The average rate of hospitalization for a generic treatment may vary from day to day (eg.: workdays vs weekend days), invalidating one of the assumptions.

### Ex 2.19
*Lake Wobegon Junior College admits students only if they score above 400 on a standardized achievement test. Applicants from group A have a mean of 500 and a standard deviation of 100 on this test, and applicants from group B have a mean of 450 and a standard deviation of 100. Both distributions are approximately normal, and both groups have the same size.*
1. *Find the proportion not admitted for each group.*
2. *Of the students who are not admitted, what proportion are from group B?*
3. *A state legislator proposes that the college lower the cutoff point for admission to 300, thinking that the proportion of not-admitted students who are from group B would decrease. If this policy is implemented, determine the effect on the answer to (2)*


**Solution**
```{r, echo=T}
#Evaluating the proportion of not admitted students using the comulative distribution function 
A_not_admitted=pnorm(400,mean=500,sd=100)
B_not_admitted=pnorm(400,mean=450,sd=100)
#This are the value of the proportion in % of the not admetted students 
A_not_admitted
B_not_admitted
#-------------------------------------------
#Since the total namber of student in each group it's the same we can evaluate the 
#propotion of not admitted student of group B among all the non admetted student like this: 
B_not_admitted/(A_not_admitted+B_not_admitted)
#-----------------------------------------------------
#Here we show that decreasing the threshold of the exam 
#the proportion of non admetted student coming from group B increase 
A_not_admitted=pnorm(300,mean=500,sd=100)
B_not_admitted=pnorm(300,mean=450,sd=100)
B_not_admitted/(A_not_admitted+B_not_admitted)

```

### Ex 2.21

*Plot the gamma distribution by fixing the shape parameter k = 3 and setting the scale parameter  = 0.5, 1, 2, 3, 4, 5. What is the effect of increasing the scale parameter? (See also Exercise 2.48.)*

**Solution**

```{r ex 2.21, echo=TRUE}
xx <- seq (0,10, l = 1000)
plot(xx, dgamma(xx, shape = 3, scale = .5), xlab ="x", ylab ="f(x)", type ="l")
lines(xx, dgamma(xx, shape = 3, scale = 1), col = 2)
lines(xx, dgamma(xx, shape = 3, scale = 2), col = 3)
lines(xx,  dgamma(xx, shape = 3, scale = 3), col = 4)
lines(xx,  dgamma(xx, shape = 3, scale = 4), col = 5)
lines(xx,  dgamma(xx, shape = 3, scale = 5), col = 6)

```

Looking at the plot we can see that Mean and standard deviation both increase(their values are proportional to 1/λ).

### Ex 2.27

*The distribution of* $X$ *= heights (cm) of women in the U.K. is approximately* $N(162,7^2)$*. Conditional on* $X = x$*, suppose* $Y$ *= weight (kg) has a* $N(3.0 + 0.40x, 8^2)$ *distribution. Simulate and plot 1000 observations from this approximate bivariate normal distribution. Approximate the marginal means and standard deviations for* $X$ *and* $Y$*. Approximate and interpret the correlation.*

**Solution**

Let's simulate and plot 1000 observations:

```{r, echo=T}
x = rnorm(n=1000, mean=162, sd=7)
y = rnorm(n=1000, mean=3+0.4*x, sd=8)
plot(x, y)
```

Let's approximate the marginal means and standard deviations:

```{r, echo=T}
mean(x); mean(y); sd(x); sd(y)
```

Let's approximate the correlation:

```{r, echo=T}
cor(x, y)
```

$X$ and $Y$ are slightly positively correlated, that is: when $X$ > mean(x) then typically $Y$ > mean(y), and when $X$ < mean(x) then typically $Y$ < mean(y).

### Ex 2.52
*The pdf $f$ of a $N(\mu,\sigma)$ distribution can be derived from the standard normal pdf $\phi(z)=\frac{1}{\sqrt{2\pi}}e^{-\frac{z^2}{2}}\: whit\:z\in(-\infty,\infty)$.*
1. *Show that the normal cdf $F$ relates to the standard normal cdf $\Phi$ by $F[y]=\Phi[\frac{y-\mu}{\sigma}]$.*
1. *From (1), show that $f(y)=\frac{1}{\sigma}\phi(\frac{y-\mu}{\sigma})$, and show that $f(y;\mu,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{(y-\mu)^2}{2\sigma}}$.*


**Solution**


Abbiamo che $F(y)=\int^y_{-\infty}f(z)dz$ while $\Phi(y)=\int^y_{-\infty}\phi(z)dz$ so $\Phi[\frac{y-\mu}{\sigma}]=\int^{\frac{y-\mu}{\sigma}}_{-\infty}\phi(z) dz$ and  making a change of variable from $z$ to $z'=z\sigma+\mu$ we obtain
$$
\int^{\frac{y-\mu}{\sigma}}_{-\infty}\phi(z) dz=\int^y_{-\infty}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(z'-\mu)^2}{2\sigma^2}} dz'
$$
That is exactly $F[y]$. Furthermore from $F[y]=\int^y_{-\infty}f(z)dz=\Phi[\frac{y-\mu}{\sigma}]=\int^y_{-\infty}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(z'-\mu)^2}{2\sigma^2}} dz'=\int^y_{-\infty}\frac{1}{\sigma}\phi(\frac{(z-\mu)^2}{\sigma}) dz'\: \forall y$ we can affirm that $f(y)=\frac{1}{\sigma}\phi(\frac{(z-\mu)^2}{\sigma})$.


### Ex 2.53

*If $Y$ is a standard normal random variable, with cdf $\Phi$, what is the probability distribution of $X=\Phi(Y)$? Illustrate by randomly generating a million standard normal random variables, applying the cdf function $\Phi$ to each, and plotting histograms of the (a) $y$ values, (b) $x$ values.*

**Solution**


I'll suppose that the random variable $\Phi(Y)$, with $\Phi$ the cdf of the standard normal distribution, will have a distribution function that is the uniform distribution function since the cdf of a random variable has the property to give a uniform distributed random variable if evaluated on the random variable itself.
```{r, echo=T}
#Generating a sample of one million of variable with standard normal distribution 
y=rnorm(1000000,mean=0,sd=1)
#Generating the sample of one million of random variable x that correspond to the cdf evaluated on y 
x=pnorm(y,mean=0,sd=1)
#Comparign the histogram of the two samples
par(mfrow=c(1,2))
hist(y,freq = F)
curve(dnorm(x, mean=0, sd=1), add=TRUE, lty=1, col=2) 
hist(x,freq = F)
curve(dunif(x), add=TRUE, lty=1, col=2) 
```

### Ex 2.67

*For n observations {*$y_i$*}, let *$y_{(1)}$ *≤ *$y_{(2)}$ *≤ ⋯ ≤*$y_{(n)}$ *denote their ordered values, called order statistics. Let *$q_i$ *be the i/(n + 1) quantile of the standard normal distribution, for  i = 1...., n. When {*$y_i$*} are a random sample from a normal distribution, the plot of the points  (*$q_{(1)}$ *, *$y_{(1)}$ *),..., (*$q_{(n)}$ *,*$y_{(n)}$ *) should approximately follow a straight line, more closely so when n is  large. This normal quantile plot is a special case of a quantile-quantile (Q-Q) plot. The  R appendix of this book presents details.*                                                                  
*(a) Randomly generate (i) n = 10, (ii) n = 100, (iii) n = 1000 observations from a N(0, 1)  distribution and construct the normal quantile plot each time, using software such as the  R functions rnorm and qqnorm. Note that as n increases the points cluster more tightly  along the line y = x, which you can add to the plot with command abline(0, 1).*                                                              
*(b) Randomly generate 1000 observations from a N(100, 162) distribution of IQ’s and construct the normal quantile plot. What is the slope of the line approximating these points?  *                                                                          
*(c) Randomly generate 1000 observations from the (i) exponential distribution (2.2), (ii) uniform distribution over (0, 1), using software such as the R functions rexp and runif. Construct the normal quantile plot in each case. Explain how they reveal the non-normality  of the data. *

*(d) For case (ii) in (c), find appropriate uniform quantiles for which the Q-Q plot would be  approximately linear. Construct the plot.*

**Solution**

a)
```{r ex 2.67 a, echo=TRUE}     
Y10 <-rnorm(10)
Y100 <-rnorm(100)
Y1000 <-rnorm(1000)

qqnorm(Y10,col='blue',main='Y10~ N(0,1)'); abline(0,1)
qqnorm(Y100,col='blue',main='Y100~ N(0,1)'); abline(0,1)
qqnorm(Y1000,col='blue',main='Y1000~ N(0,1)'); abline(0,1)
```

as n increase points cluster more close to the y = x line

b)
```{r ex 2.67 b, echo=TRUE}
yb <- rnorm(1000, 0, 16)
qqnorm(yb)
abline(0,16)
```

we change the values of abline() function and we find out that the slope of points is about 16

c)
the plot for the exponential distribution shows that, since the distribution is right skewed, there are some quite large observations but no very small observations, reflecting its lower boundary of 0 for possible values.

```{r ex 2.67 c part a, echo=TRUE}
ye <- rexp(1000)

qqnorm(ye,col='blue', main='Y3 ~ exp(1)') 
```

the plot for the uniform distribution shows that there are fewer observations in the tails than expected with normal distribution.

```{r ex 2.67 c part b, echo=TRUE}
yu <- runif(1000)

qqnorm(yu, col='blue', main='Y4 ~ uniform(0,1)')  
```

d) 

qunif gives the quantile function for the uniform distribution;
c(1:n)/(n+1) is the vector evaluated as in the text of the exercise 
"Let $q_i$ be the i~(n + 1) quantile of the standard normal distribution ,for
i = 1. ...,n."
we sort the vector of values generated from runif()
we build the plot that compares sorted values of yu with quantiles found before

```{r ex 2.67 d, echo=TRUE}
yu <- runif(1000)
n=1000
q=qunif(c(1:n)/(n+1))
yu=sort(yu)
plot(q,yu)

```

so for the uniform(0,1) the appropriate quantiles are $q_i$ = i/(n+1)

### Ex 2.71

*When* $Y$ *has positively skewed distribution over the positive real line, statistical analyses often treat* $X = log(Y)$ *as having a* $N(\mu, \sigma^2)$ *distribution. Then* $Y$ *is said to have the log-normal distribution.*

a. *Derive an expression for the c.d.f.* $G$ *of* $Y$ *in terms of the c.d.f.* $F$ *of* $X$*, and take the derivative to obtain the p.d.f.* $g$ *of* $Y$*.*
b. *Use the information given in Exercise 2.66 about the m.g.f. of a normal random variable to show that* $E(Y) = e^{\mu + \sigma^2/2}$ *and* $var(Y) = [e^{\sigma^2} − 1][E(Y)]^2$*. As shown for the gamma distribution in Exercise 2.45, the log-normal has standard deviation proportional to the mean.*
c. *Explain why the median of the distribution of* $Y$ *is* $e^\mu$*. What do the mean and median suggest about the skewness of the distribution?*
d. *For independent observations* $y_1,...,y_n$ *from the log-normal, we could summarize the distribution by finding* $\bar x$ *for* $\{x_i =log(y_i)\}$ *and then using* $exp(\bar x)$*. Show that* $\begin{matrix} exp(\bar x) = (\prod_i y_i)^{1/n} \end{matrix}$*, the geometric mean of* $\{y_i\}$*.*

**Solution**

**(a)** <br>
Let's express $G$ in terms of $F$:

$$
G(y) = Pr(Y \le y) = Pr[log(Y) \le log(y)] = Pr[X \le log(y)] = F[log(y)]
$$

Let's obtain $g$:

$$
g(y) = {d \over dy}G(y) = {d \over dy}F[log(y)] \overset{\text{chain rule}}= {1 \over y}f[log(y)]
$$

Since $f$ is the p.d.f of a normal distribution:

$$
g(y) = {1 \over y} \left( \frac{1}{\sigma \sqrt{2\pi}} exp \left[-{1 \over 2} \left( \frac{log(y) - \mu}{\sigma} \right)^2 \right] \right)
$$

**(b)** <br>
The Exercise 2.66 says that the moment generating function m.g.f. of a normal random variable $X$ is:

$$
m(t) := E(e^{tX}) = e^{\mu t + \sigma^2 t^2/2}
$$

Let's show that $E(Y) = e^{\mu + \sigma^2/2}$:

$$
X = log(Y) \implies Y = e^X \implies E(Y) = E(e^X) \overset{\text{ex 2.66}}= e^{\mu + \sigma^2/2}
$$
Note that $E(Y)^2 = e^{\mu 2 + \sigma^2}$ (let's call this expression "expr 1"). <br>
Let's show that $var(Y) = [e^{\sigma^2} − 1][E(Y)]^2$:

$$
var(Y) := E(Y^2) - E(Y)^2 = E(e^{2X}) - E(Y)^2 \overset{\text{ex 2.66}}= e^{\mu 2 + \sigma^2 2} - E(Y)^2 = \\
e^{\mu 2 + \sigma^2} e^{\sigma^2} - E(Y)^2 \overset{\text{expr 1}}= E(Y)^2e^{\sigma^2} - E(Y)^2 = E(Y)^2(e^{\sigma^2} − 1)
$$

**(c)** <br>
Since $X$ is normally distributed, its median is equal to its mean $\mu$, so $Pr(X \le \mu) = 0.5$. <br>
Let's show why the median of the distribution of $Y$ is $e^\mu$:

$$
Pr(X \le \mu) = 0.5 \implies Pr(log(Y) \le \mu) = 0.5 \implies Pr(Y \le e^\mu) = 0.5
$$

The median of the distribution of $Y$ is smaller than its mean and this suggests that the distribution is positively skewed.

**(d)** <br>
They are equal:

$$
exp(\bar x) = exp \left( {1\over n} \sum_i x_i \right) = exp \left( {1\over n} \sum_i log(y_i) \right) = \\
exp \left( \sum_i log(y_i^{1/n}) \right) = \prod_i exp[log(y_i^{1/n})] =
\left( \prod_i y_i \right)^{1/n}
$$

## CS - Chapter 1

### Ex 1.1
*Exponential random variable, $X\ge0$, has pdf $f(x)=\lambda e^{-\lambda x}$.*
1. *Find the cdf and the quantile function for $X$.*
2. *Find $Pr(X<\lambda)$ and the median of $X$.*
3. *Find the mean and variance of $X$.*


**Solution**

1. The cdf is defined as $F(y)=\int_0^yf(x)dx$ and so we obtain $F[y]=\int_0^y\lambda e^{-\lambda x}dx=1-e^{-\lambda y}$. The quantile function is defined as $F^{-1}[y]$ and so we have $Q_y=\frac{-log(1-y)}{\lambda}$.
2. $Pr(X<\lambda)=F[\lambda]=1-e^{-\lambda^2}$, while the median is $Q_{0.5}=\frac{-log(0.5)}{\lambda}=\frac{0.7}{\lambda}$. 
3. The mean is $E[x]=\int_0^\infty xf(x)dx=\int_0^\infty x\lambda e^{-\lambda x}dx$ and using integration by parts we obtain $E[X]=\frac{x}{\lambda}e^{-\lambda x}|_\infty^0+\int^0_\infty -\frac{e^{-\lambda x}}{\lambda}dx=\frac{1}{\lambda}$. For the variance we evaluate $var(x)=E[x^2]+E^2[x]$ adn with the same procedure we obtain $var(x)=\frac{2}{\lambda^2}-\frac{1}{\lambda^2}=\frac{1}{\lambda^2}$


### Ex 1.2

*Evaluate* $Pr(X < 0.5, Y < 0.5)$ *if* $X$ *and* $Y$ *have the following joint p.d.f.*
$$
f(x,y) = \begin{cases}
  x+3y^2/2 & 0<x<1 \;\&\; 0<y<1 \\
  0 & \text{otherwise}.
\end{cases}
$$

**Solution**

The probability corresponds to the volume under the portion of interest in the graph:

$$
\int_0^{1\over2} \int_0^{1\over2} x+{3\over2}y^2 \,dx\,dy =
\int_0^{1\over2} \left[ {x^2\over2} + {3\over2}y^2x \right]_0^{1\over2} \,dy =
\int_0^{1\over2} {1\over8}+{3\over4}y^2 \,dy =
\left[ {1\over8}y + {1\over4}y^3 \right]_0^{1\over2} = {3\over32}
$$

### Ex 1.8 

*If *$log(x) ∼ N(μ,σ^2)$*, find the p.d.f. of X.*

**Solution**

Given that $log(x) ∼ N(μ,σ^2)$

The cumulative distribution function of X is,

$$=F_x(X) $$
$$=Pr[X \leq x] $$

applying logarithm and operations that preserve inequality direction

$$=Pr[logX \leq log x] ; x > 0 $$
$$=Pr \left[ \frac{logX - \mu}{\sigma} \leq \frac{logx - \mu}{\sigma}\right] ; x > 0 $$
$$=\Phi \left( \frac{logx - \mu}{\sigma} \right) ; x > 0 $$
that is the probability of the cumulative function of the normal standard distribution

the pdf of X is
$$= f_x(x) $$
$$= \frac{d}{dx} F_x(X) $$

$$= \phi \left( \frac{log x - \mu}{\sigma} \right) \frac{1}{x\sigma} ; x > 0 $$
$$=\frac{1}{x\sigma \sqrt 2\pi}e^{- \frac{1}{2} \left( \frac{log x - \mu}{\sigma}  \right)^2}  ; 0 < x < \infty $$
X follows log normal distribution

## CS - Chapter 3

### Ex 3.3

*Rewrite the following, replacing the loop with efficient code:*
```
n <- 100000; z <- rnorm(n)
zneg <- 0; j <- 1

for (i in 1:n) {
  if (z[i]<0) {
    zneg[j] <- z[i]
    j <- j + 1
  }
}
```
*Confirm that your rewrite is faster but gives the same result.*

**Solution**

Let's time the original code:

```{r, echo=T}
n <- 100000; z <- rnorm(n)
zneg <- 0; j <- 1

system.time( #time the original code
  for (i in 1:n) {
    if (z[i]<0) {
      zneg[j] <- z[i]
      j <- j + 1
    }
  }
)
```

Let's time the rewritten code:

```{r, echo=T}
system.time(
  opt_zneg <- z[z<0] #rewritten code
)
```

Let's ensure both codes give the same result:

```{r, echo=T}
all(zneg == opt_zneg)
```

The rewrite is faster and gives the same result.


### Ex 3.6 

*The empirical cumulative distribution function for a set of measurements {*$x_i$ 
*: i = 1, . . . n} is*
$$\hat{F}(x) = \frac{\#{x_i < x}}{n}$$
*where #{*$x_i$*< x} denotes ‘number of *$x_i$ *values less than x’. When answering the following, try to ensure that your code is commented, clearly structured, and tested. To test your code, generate random samples using rnorm, runif, etc.*

*a. Write an R function that takes an unordered vector of observations x and returns the values of the empirical c.d.f. for each value, in the order corresponding to the original x vector. See ?sort.int.*

*b. Modify your function to take an extra argument plot.cdf, that when TRUE will cause the empirical c.d.f. to be plotted as a step function over a suitable x range.*

**Solution**

a) 

the function is cdf(x) and takes in the set of observed values x.

Declare variable x_m denoting set of measured values.

First sort the elements of x_m using sort().
 
Then using while loop for set of observed values check for how many number of x_m’s is x_m
 
Print cdf of each element of x.


```{r ex 3.6 a, echo=TRUE}
#defining cdf function
cdf <- function(x){
  n<- 1000 # number of samples in measurements
  x_m <- rnorm(n,0,n/2) #generate set of measurements
  x_m <- sort(x_m) #sort measurements
  cdf <- c() #initialize vector for cdf
  
  for (i in 1:length(x)){
    j <- 1 #initialize the variable to count #(x_m[j]<x[i])
    while((x_m[j]<x[i])&& (j-1)<length(x_m)){
      j <- j+1  #increase j in case x_m[j]<x[i]
    }
    cdf <- c(cdf, ((j-1)/length(x_m))) #add cdf of x[i]
  }
  
  #print cdf of each corresponding x
  print("Corresponding c.d.f.")
  print(cdf)
    
}
#end of function

#generate observations
n<- 20
m <- 0
x<- rnorm(n,m,n)
print("observed values")
print(x)

#calling the function
cdf(x)

```

b)

Add an argument plot.cdf which when TRUE the next process continues to get stepwise plot.

Sort elements of x and cdf using sort.

Using plot function with type ’s’ plot the step function of c.d.f. with respect to observed values.

```{r ex 3.6 b, echo=TRUE}
cdf <- function(x,plot.cdf){
  n<- 1000 # number of samples
  x_m <- rnorm(n,0,n/2) #generate set of measurements
  x_m <- sort(x_m) #sort measurements
  cdf <- c() #initialize vector for cdf
  
  for (i in 1:length(x)){
    j <- 1
    while((x_m[j]<x[i])&& (j-1)<length(x_m)){
      j <- j+1      
    }
    cdf <- c(cdf, ((j-1)/length(x_m)))
  }
  
  #print cdf of each corresponding x
  print("Corresponding c.d.f.")
  print(cdf)
  
  
    
    #for plotting cdf in the form of steps
    if(plot.cdf == TRUE){
      
      x<-sort(x)
      cdf<- sort(cdf)
      plot(x,cdf,type='s',xlab="Observed values", ylab = "c.d.f.")
    }
    
    
}

#generate observations
n<- 20
m <- 0
x<- rnorm(n,m,n)
print("observed values")
print(x)
plot.cdf <- TRUE

#calling the function
cdf(x,plot.cdf)

```